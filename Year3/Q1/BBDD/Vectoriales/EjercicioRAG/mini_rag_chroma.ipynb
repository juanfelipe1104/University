{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1200d60f",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13d888b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37639819",
   "metadata": {},
   "source": [
    "# Constantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf3126fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del documento\n",
    "DOC_PATH = \"./test.txt\"\n",
    "\n",
    "# Directorio de la base de datos Chroma\n",
    "CHROMA_DIR = \"./chroma_db\"\n",
    "\n",
    "# Nombre de la colección\n",
    "COLLECTION_NAME = \"mini_rag_docs\"\n",
    "\n",
    "# Tamaño de los chunks\n",
    "CHUNK_SIZE = 900\n",
    "\n",
    "# Solapamiento entre chunks\n",
    "OVERLAP = 200      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4e3ac",
   "metadata": {},
   "source": [
    "# Leer documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "012504ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path: str, encoding: str = \"utf-8\") -> str:\n",
    "    with open(path, \"r\", encoding=encoding, errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_document(path: str) -> tuple[str, dict]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"No existe: {path}\")\n",
    "    text = read_txt(path)\n",
    "    meta = {\n",
    "        \"source\": os.path.basename(path),\n",
    "        \"path\": os.path.abspath(path),\n",
    "        \"loaded_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    return text, meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcfd05d",
   "metadata": {},
   "source": [
    "# Limpieza del texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a096d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_basic(text: str) -> str:\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 800, overlap: int = 150) -> list[str]:\n",
    "    if chunk_size <= 0:\n",
    "        raise ValueError(\"chunk_size debe ser > 0\")\n",
    "    if overlap < 0:\n",
    "        raise ValueError(\"overlap debe ser >= 0\")\n",
    "    if overlap >= chunk_size:\n",
    "        raise ValueError(\"overlap debe ser < chunk_size\")\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(text)\n",
    "    while start < n:\n",
    "        end = min(start + chunk_size, n)\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        if end == n:\n",
    "            break\n",
    "        start = end - overlap\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844a111",
   "metadata": {},
   "source": [
    "# Crear indice en Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c54f3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings locales\n",
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"  # 384 dimensiones\n",
    ")\n",
    "\n",
    "# Cliente Chroma\n",
    "client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "\n",
    "\n",
    "def get_collection(name: str):\n",
    "    return client.get_or_create_collection(\n",
    "        name=name,\n",
    "        metadata={\"hnsw:space\": \"cosine\"},\n",
    "        embedding_function=ef,\n",
    "    )\n",
    "\n",
    "\n",
    "def reset_collection(name: str):\n",
    "    try:\n",
    "        client.delete_collection(name)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return get_collection(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6256730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chroma_index(doc_path: str, collection_name: str, chunk_size: int, overlap: int, reset: bool = True):\n",
    "    # Cargar\n",
    "    raw_text, doc_meta = load_document(doc_path)\n",
    "    text = clean_text_basic(raw_text)\n",
    "\n",
    "    # Trocear\n",
    "    chunks = chunk_text(text, chunk_size=chunk_size, overlap=overlap)\n",
    "\n",
    "    # Colección\n",
    "    col = reset_collection(collection_name) if reset else get_collection(collection_name)\n",
    "\n",
    "    # Insertar\n",
    "    ids = [f\"{doc_meta['source']}::chunk_{i}\" for i in range(len(chunks))]\n",
    "    metadatas = []\n",
    "    for i in range(len(chunks)):\n",
    "        metadatas.append({\n",
    "            \"source\": doc_meta[\"source\"],\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_size\": chunk_size,\n",
    "            \"overlap\": overlap,\n",
    "        })\n",
    "\n",
    "    # Añadir a la colección\n",
    "    col.add(ids=ids, documents=chunks, metadatas=metadatas)\n",
    "\n",
    "    info = {\n",
    "        \"doc\": doc_meta,\n",
    "        \"n_chunks\": len(chunks),\n",
    "        \"collection\": collection_name,\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"overlap\": overlap,\n",
    "        \"built_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"persist_dir\": os.path.abspath(CHROMA_DIR),\n",
    "    }\n",
    "    return col, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8832e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': {'source': 'test.txt',\n",
       "  'path': '/home/juan/BBDD/EjercicioRAG/test.txt',\n",
       "  'loaded_at': '2026-01-20 19:45:17'},\n",
       " 'n_chunks': 7,\n",
       " 'collection': 'mini_rag_docs',\n",
       " 'chunk_size': 900,\n",
       " 'overlap': 200,\n",
       " 'built_at': '2026-01-20 19:45:18',\n",
       " 'persist_dir': '/home/juan/BBDD/EjercicioRAG/chroma_db'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection, build_info = build_chroma_index(\n",
    "    doc_path=DOC_PATH,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    overlap=OVERLAP,\n",
    "    reset=True,\n",
    ")\n",
    "\n",
    "build_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1f6b4",
   "metadata": {},
   "source": [
    "# Consultas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5f4f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query: str, top_k: int = 5, show_chars: int = 350):\n",
    "    res = collection.query(query_texts=[query], n_results=top_k)\n",
    "\n",
    "    docs = res.get(\"documents\", [[]])[0]\n",
    "    metas = res.get(\"metadatas\", [[]])[0]\n",
    "    dists = res.get(\"distances\", [[]])[0]\n",
    "\n",
    "    print(\"PREGUNTA:\", query)\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    for i, (doc, meta, dist) in enumerate(zip(docs, metas, dists), start=1):\n",
    "        sim = None\n",
    "        if dist is not None:\n",
    "            sim = 1 - float(dist)\n",
    "        src = meta.get(\"source\") if isinstance(meta, dict) else None\n",
    "        idx = meta.get(\"chunk_index\") if isinstance(meta, dict) else None\n",
    "\n",
    "        line = f\"[{i}] sim={sim:.4f}  dist={dist:.4f}  source={src}  chunk={idx}\"\n",
    "        print(line)\n",
    "        snippet = (doc or \"\")[:show_chars].replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        print(\" \", snippet + (\" ...\" if (doc and len(doc) > show_chars) else \"\"))\n",
    "        print(\"-\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754d872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREGUNTA: ¿De qué trata el documento?\n",
      "==========================================================================================\n",
      "[1] sim=0.6014  dist=0.3986  source=test.txt  chunk=2\n",
      "  n numérica (vector) de un texto. Se genera usando un modelo entrenado, por ejemplo Sentence Transformers. La idea es que textos con significado similar tengan embeddings similares.  Ejemplo: - \"¿Qué es Chroma?\" y \"Explícame la librería Chroma DB\" deberían producir embeddings cercanos. - \"Cómo cocinar arroz\" debería estar lejos de \"optimización de b ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[2] sim=0.5271  dist=0.4729  source=test.txt  chunk=0\n",
      "  TEMA: INTRODUCCIÓN A SISTEMAS DE RECUPERACIÓN DE INFORMACIÓN Y RAG  1. ¿Qué es un sistema de Recuperación de Información? Un sistema de Recuperación de Información (Information Retrieval, IR) es un conjunto de técnicas y herramientas que permiten buscar información relevante dentro de una colección de documentos. A diferencia de una búsqueda por co ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[3] sim=0.5156  dist=0.4844  source=test.txt  chunk=1\n",
      "  pueden fallar si el usuario no formula la consulta con las mismas palabras exactas que aparecen en el texto.  2. ¿Qué es una base de datos vectorial? Una base de datos vectorial es un tipo de almacenamiento especializado en guardar vectores numéricos (embeddings) asociados a fragmentos de texto, imágenes u otros tipos de información. Estos vectores ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[4] sim=0.5122  dist=0.4878  source=test.txt  chunk=6\n",
      "  os más relevantes con ciertos parámetros.  Ejemplos de preguntas recomendadas: - ¿Qué es RAG? - ¿Qué es un embedding? - ¿Para qué sirve una base de datos vectorial? - ¿Qué parámetros se ajustan en el chunking? - ¿Qué hace Chroma en un sistema RAG?  9. Conclusión Un mini sistema RAG permite construir una base sólida para aplicaciones más avanzadas c ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[5] sim=0.5083  dist=0.4917  source=test.txt  chunk=5\n",
      "  ligera que puede ejecutarse en local y persistir en disco. Normalmente se usa en Python con estos pasos: - Crear un cliente persistente (PersistentClient) - Crear una colección - Insertar documentos con ids y metadata - Consultar con query()  Chroma permite agregar metadatos como: - nombre de archivo fuente - índice de chunk - ruta del documento -  ...\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ask(\"¿De qué trata el documento?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4585c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREGUNTA: ¿Qué significa RAG?\n",
      "==========================================================================================\n",
      "[1] sim=0.5045  dist=0.4955  source=test.txt  chunk=6\n",
      "  os más relevantes con ciertos parámetros.  Ejemplos de preguntas recomendadas: - ¿Qué es RAG? - ¿Qué es un embedding? - ¿Para qué sirve una base de datos vectorial? - ¿Qué parámetros se ajustan en el chunking? - ¿Qué hace Chroma en un sistema RAG?  9. Conclusión Un mini sistema RAG permite construir una base sólida para aplicaciones más avanzadas c ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[2] sim=0.4611  dist=0.5389  source=test.txt  chunk=2\n",
      "  n numérica (vector) de un texto. Se genera usando un modelo entrenado, por ejemplo Sentence Transformers. La idea es que textos con significado similar tengan embeddings similares.  Ejemplo: - \"¿Qué es Chroma?\" y \"Explícame la librería Chroma DB\" deberían producir embeddings cercanos. - \"Cómo cocinar arroz\" debería estar lejos de \"optimización de b ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[3] sim=0.3791  dist=0.6209  source=test.txt  chunk=5\n",
      "  ligera que puede ejecutarse en local y persistir en disco. Normalmente se usa en Python con estos pasos: - Crear un cliente persistente (PersistentClient) - Crear una colección - Insertar documentos con ids y metadata - Consultar con query()  Chroma permite agregar metadatos como: - nombre de archivo fuente - índice de chunk - ruta del documento -  ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[4] sim=0.3476  dist=0.6524  source=test.txt  chunk=4\n",
      "  as y baja la precisión.  Normalmente se ajustan dos parámetros: - chunk_size: tamaño del fragmento (por ejemplo 600 a 1200 caracteres). - overlap: superposición entre fragmentos (por ejemplo 100 a 250 caracteres).  Un overlap ayuda a que ideas que quedan “entre dos chunks” no se pierdan.  6. Ejemplo de funcionamiento (conceptual) Supongamos que ten ...\n",
      "------------------------------------------------------------------------------------------\n",
      "[5] sim=0.3246  dist=0.6754  source=test.txt  chunk=1\n",
      "  pueden fallar si el usuario no formula la consulta con las mismas palabras exactas que aparecen en el texto.  2. ¿Qué es una base de datos vectorial? Una base de datos vectorial es un tipo de almacenamiento especializado en guardar vectores numéricos (embeddings) asociados a fragmentos de texto, imágenes u otros tipos de información. Estos vectores ...\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ask(\"¿Qué significa RAG?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
