{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# NLP TO CLASIFY SPAM/NOT SPAM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "El objetivo de este proyecto es desarrollar un sistema de clasificación binaria capaz de distinguir entre mensajes **SPAM** y **NO SPAM** utilizando técnicas de *Natural Language Processing* (NLP). Este tipo de problema es especialmente relevante en aplicaciones reales, donde es fundamental filtrar contenido no deseado de forma automática y robusta.\n",
    "\n",
    "Para abordar la tarea, se comienza implementando un **modelo NLP básico**, basado en un preprocesado clásico del texto y una representación vectorial mediante **TF-IDF**, junto con un clasificador lineal. Sobre este modelo inicial se realiza un proceso de **optimización de hiperparámetros** con el objetivo de maximizar la métrica oficial de la competición, **Matthews Correlation Coefficient (MCC)**, especialmente adecuada en escenarios con posible desbalanceo entre clases.\n",
    "\n",
    "Una vez establecido este baseline, el proyecto explora un enfoque más avanzado basado en **transfer learning**, utilizando un modelo de lenguaje preentrenado (**DistilBERT**). En esta segunda fase se reaprovechan representaciones semánticas aprendidas previamente a gran escala, aplicando primero entrenamiento de la cabeza de clasificación y posteriormente **fine-tuning** parcial del modelo para adaptarlo al dominio específico del problema.\n",
    "\n",
    "De este modo, el proyecto permite comparar un enfoque clásico de NLP con uno moderno basado en *Transformers*, analizando sus diferencias en complejidad, rendimiento y capacidad de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:56:23.965522Z",
     "iopub.status.busy": "2025-12-12T20:56:23.964578Z",
     "iopub.status.idle": "2025-12-12T20:56:23.970366Z",
     "shell.execute_reply": "2025-12-12T20:56:23.969568Z",
     "shell.execute_reply.started": "2025-12-12T20:56:23.965495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Pandas para dataframes\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 36)\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n",
    "\n",
    "# Product para simular GridSearch\n",
    "from itertools import product\n",
    "\n",
    "# Modelo básico\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# competition metric for local evaluation\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar el dataset\n",
    "\n",
    "En esta sección cargamos los datos del dataset y creamos los distintos subconjuntos (train, validation, test)\n",
    "\n",
    "Los datos de entrenamiento y testeo se encuentran en archivos csv. Los leemos usando pandas\n",
    "\n",
    "Para los datos de entrenamiento (train), vamos a reservar el 20% para validación, así evaluamos el rendimiento del modelo durante el entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:56:27.262254Z",
     "iopub.status.busy": "2025-12-12T20:56:27.261680Z",
     "iopub.status.idle": "2025-12-12T20:56:27.375120Z",
     "shell.execute_reply": "2025-12-12T20:56:27.374454Z",
     "shell.execute_reply.started": "2025-12-12T20:56:27.262228Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are everywhere dirt, on the floor, the windows, even on my shirt. And sometimes when i open my mouth, you are all that comes flowing out. I dr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: \\nmon , 24 may 2004 12 : 14 : 06 - 0600\\ni am taking the liberty of writing you this\\nletter instead of interrupting you\\nby phone . plea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So the sun is anti sleep medicine.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey are you angry with me. Reply me dr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ü go home liao? Ask dad to pick me up at 6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7092</th>\n",
       "      <td>I stayed at this hotel over the weekend of the Chicago Bears Fan Convention (Feb 27- March 1). The hotel is beautiful. I had a Towers room. I had ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>Subject: eis invoices for may\\ni just wanted to make all of you aware of the message below from financial\\noperations . when you review your rc re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>Ok... The theory test? when are ü going to book? I think it's on 21 may. Coz thought wanna go out with jiayin. But she isnt free</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>January Male Sale! Hot Gay chat now cheaper, call 08709222922. National rate from 1.5p/min cheap to 7.8p/min peak! To stop texts call 08712460324 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>My husband and I were planning our 1st year wedding anniversary and we wanted to go back and spend it in Chicago where we had first met. After spe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7097 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         text  \\\n",
       "row_id                                                                                                                                                          \n",
       "0       You are everywhere dirt, on the floor, the windows, even on my shirt. And sometimes when i open my mouth, you are all that comes flowing out. I dr...   \n",
       "1       Subject: \\nmon , 24 may 2004 12 : 14 : 06 - 0600\\ni am taking the liberty of writing you this\\nletter instead of interrupting you\\nby phone . plea...   \n",
       "2                                                                                                                          So the sun is anti sleep medicine.   \n",
       "3                                                                                                                     Hey are you angry with me. Reply me dr.   \n",
       "4                                                                                                               Ü go home liao? Ask dad to pick me up at 6...   \n",
       "...                                                                                                                                                       ...   \n",
       "7092    I stayed at this hotel over the weekend of the Chicago Bears Fan Convention (Feb 27- March 1). The hotel is beautiful. I had a Towers room. I had ...   \n",
       "7093    Subject: eis invoices for may\\ni just wanted to make all of you aware of the message below from financial\\noperations . when you review your rc re...   \n",
       "7094                         Ok... The theory test? when are ü going to book? I think it's on 21 may. Coz thought wanna go out with jiayin. But she isnt free   \n",
       "7095    January Male Sale! Hot Gay chat now cheaper, call 08709222922. National rate from 1.5p/min cheap to 7.8p/min peak! To stop texts call 08712460324 ...   \n",
       "7096    My husband and I were planning our 1st year wedding anniversary and we wanted to go back and spend it in Chicago where we had first met. After spe...   \n",
       "\n",
       "        spam_label  \n",
       "row_id              \n",
       "0                0  \n",
       "1                1  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "7092             0  \n",
       "7093             0  \n",
       "7094             0  \n",
       "7095             1  \n",
       "7096             1  \n",
       "\n",
       "[7097 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col = \"row_id\")\n",
    "\n",
    "# Train / Validation split\n",
    "X = train[\"text\"].values\n",
    "y = train[\"spam_label\"].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:56:30.082722Z",
     "iopub.status.busy": "2025-12-12T20:56:30.082452Z",
     "iopub.status.idle": "2025-12-12T20:56:30.141532Z",
     "shell.execute_reply": "2025-12-12T20:56:30.140870Z",
     "shell.execute_reply.started": "2025-12-12T20:56:30.082700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>Subject: king ranch processed volumes at tailgate\\nd .\\nmary provided this to brian , please check against your numbers asap\\n- - - - - - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>Subject: cialis , viagra , xanax , valium at low price ! no prescription needed !\\ndiscount rx is simple , quick , and affordable ! br\\noffering m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>Subject: september deal inactivation in sitara\\ncurrently , prior month deals are inactivated in sitara for portfolio\\npurposes on the 10 th of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>Subject: jan . 01 sale to texas general land office\\nlinda -\\ni did not know that this was part of a natural gas / crude oil exchange deal\\nand bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>Subject: 5 th changes @ duke and air liquide\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 02 / 04 / 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11824</th>\n",
       "      <td>Subject: contract obligations\\ncharlie ,\\nhere is a breakout for the volumes that have been paid on . we are off by\\napproximately 20000 according...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11825</th>\n",
       "      <td>For a hotel rated with four diamonds by AAA, one would think the Hilton Chicago would be almost like staying at a palace with royalty. The only ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11826</th>\n",
       "      <td>We spend our days waiting for the ideal path to appear in front of us.. But what we forget is.. \"paths are made by walking.. not by waiting..\" Goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>Subject: request submitted : access request for lisbet . newton @ enron . com\\nyou have received this email because you are listed as a data appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11828</th>\n",
       "      <td>Subject: meter 980070\\ndaren ,\\nthis meter has recorded flow for the following days with no deal .\\n10 - 29 - 99 1300\\n10 - 30 - 99 23\\n10 - 31 - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4732 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         text\n",
       "row_id                                                                                                                                                       \n",
       "7097    Subject: king ranch processed volumes at tailgate\\nd .\\nmary provided this to brian , please check against your numbers asap\\n- - - - - - - - - - ...\n",
       "7098    Subject: cialis , viagra , xanax , valium at low price ! no prescription needed !\\ndiscount rx is simple , quick , and affordable ! br\\noffering m...\n",
       "7099    Subject: september deal inactivation in sitara\\ncurrently , prior month deals are inactivated in sitara for portfolio\\npurposes on the 10 th of th...\n",
       "7100    Subject: jan . 01 sale to texas general land office\\nlinda -\\ni did not know that this was part of a natural gas / crude oil exchange deal\\nand bi...\n",
       "7101    Subject: 5 th changes @ duke and air liquide\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by ami chokshi / corp / enron on 02 / 04 / 200...\n",
       "...                                                                                                                                                       ...\n",
       "11824   Subject: contract obligations\\ncharlie ,\\nhere is a breakout for the volumes that have been paid on . we are off by\\napproximately 20000 according...\n",
       "11825   For a hotel rated with four diamonds by AAA, one would think the Hilton Chicago would be almost like staying at a palace with royalty. The only ro...\n",
       "11826   We spend our days waiting for the ideal path to appear in front of us.. But what we forget is.. \"paths are made by walking.. not by waiting..\" Goo...\n",
       "11827   Subject: request submitted : access request for lisbet . newton @ enron . com\\nyou have received this email because you are listed as a data appro...\n",
       "11828   Subject: meter 980070\\ndaren ,\\nthis meter has recorded flow for the following days with no deal .\\n10 - 29 - 99 1300\\n10 - 30 - 99 23\\n10 - 31 - ...\n",
       "\n",
       "[4732 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col = \"row_id\")\n",
    "\n",
    "X_test = test[\"text\"].values\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo NLP básico\n",
    "\n",
    "Como primer enfoque se implementa un modelo de NLP clásico, que sirve como **baseline** para el problema de clasificación SPAM/NO SPAM. Este tipo de modelos se basa en una representación explícita del texto y en algoritmos de clasificación lineales, lo que permite una implementación sencilla, eficiente y fácilmente interpretable.\n",
    "\n",
    "El pipeline del modelo básico consta de las siguientes etapas:\n",
    "\n",
    "1. Representación del texto mediante **TF-IDF**, transformando cada mensaje en un vector numérico que refleja la importancia relativa de cada término en el mensaje.\n",
    "2. Inclusión de **n-grams**, permitiendo capturar no solo palabras individuales, sino también combinaciones frecuentes de palabras.\n",
    "3. Clasificación mediante **regresión logística**, un modelo lineal adecuado para problemas de clasificación binaria.\n",
    "\n",
    "Este modelo proporciona un punto de partida sólido sobre el cual evaluar mejoras posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros del modelo\n",
    "\n",
    "Con el objetivo de maximizar el rendimiento del clasificador, se llevó a cabo una búsqueda de hiperparámetros (*grid search manual*) sobre el vectorizador TF-IDF y el clasificador lineal. Esto permite identificar la combinación que mejor optimiza la métrica oficial de la competición, **Matthews Correlation Coefficient (MCC)**.\n",
    "\n",
    "Los hiperparámetros evaluados fueron:\n",
    "\n",
    "- **C:** parámetro de regularización del clasificador lineal (Logistic Regression). Controla el equilibrio entre ajuste del modelo y complejidad; valores mayores reducen la regularización.\n",
    "\n",
    "- **ngram_range:** tamaño de los n-grams considerados durante la vectorización. Incluir bigrams o trigrams permite capturar patrones léxicos más ricos que el simple modelo unigram.\n",
    "\n",
    "- **max_features:** número máximo de características generadas por el vectorizador TF-IDF. Este hiperparámetro controla la dimensionalidad del espacio de representación y puede influir tanto en el rendimiento como en el coste computacional.\n",
    "\n",
    "Cada combinación se entrenó sobre el conjunto de entrenamiento y se evaluó sobre un conjunto de validación independiente utilizando MCC. Finalmente, se seleccionaron los hiperparámetros con mejor desempeño para entrenar el modelo definitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:56:34.975161Z",
     "iopub.status.busy": "2025-12-12T20:56:34.974595Z",
     "iopub.status.idle": "2025-12-12T20:57:42.061755Z",
     "shell.execute_reply": "2025-12-12T20:57:42.059996Z",
     "shell.execute_reply.started": "2025-12-12T20:56:34.975139Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>max_features</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.845357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.839634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.837579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.836414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.835523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.833215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.833215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.833096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.832597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.831846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.831151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.830687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.829973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.827384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.826340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.825820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.825309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.824789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.822808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.819195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.818077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.816744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.816744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.814649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.812859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.812362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.812002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.797469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.794756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.793219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.791786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.791063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.788954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.788228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.786819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.781825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C ngram_range  max_features       MCC\n",
       "34  4.0      (1, 3)         20000  0.845357\n",
       "35  4.0      (1, 3)         40000  0.839634\n",
       "31  4.0      (1, 2)         20000  0.837579\n",
       "28  4.0      (1, 1)         20000  0.836414\n",
       "33  4.0      (1, 3)         10000  0.835523\n",
       "24  2.0      (1, 3)         10000  0.833215\n",
       "32  4.0      (1, 2)         40000  0.833215\n",
       "25  2.0      (1, 3)         20000  0.833096\n",
       "21  2.0      (1, 2)         10000  0.832597\n",
       "29  4.0      (1, 1)         40000  0.831846\n",
       "27  4.0      (1, 1)         10000  0.831151\n",
       "30  4.0      (1, 2)         10000  0.830687\n",
       "23  2.0      (1, 2)         40000  0.829973\n",
       "19  2.0      (1, 1)         20000  0.827384\n",
       "26  2.0      (1, 3)         40000  0.826340\n",
       "22  2.0      (1, 2)         20000  0.825820\n",
       "20  2.0      (1, 1)         40000  0.825309\n",
       "18  2.0      (1, 1)         10000  0.824789\n",
       "9   1.0      (1, 1)         10000  0.822808\n",
       "11  1.0      (1, 1)         40000  0.819195\n",
       "10  1.0      (1, 1)         20000  0.818077\n",
       "12  1.0      (1, 2)         10000  0.816744\n",
       "16  1.0      (1, 3)         20000  0.816744\n",
       "13  1.0      (1, 2)         20000  0.814649\n",
       "17  1.0      (1, 3)         40000  0.812859\n",
       "15  1.0      (1, 3)         10000  0.812362\n",
       "14  1.0      (1, 2)         40000  0.812002\n",
       "7   0.5      (1, 3)         20000  0.797469\n",
       "6   0.5      (1, 3)         10000  0.794756\n",
       "3   0.5      (1, 2)         10000  0.793219\n",
       "0   0.5      (1, 1)         10000  0.791786\n",
       "4   0.5      (1, 2)         20000  0.791063\n",
       "8   0.5      (1, 3)         40000  0.788954\n",
       "1   0.5      (1, 1)         20000  0.788228\n",
       "5   0.5      (1, 2)         40000  0.786819\n",
       "2   0.5      (1, 1)         40000  0.781825"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": [0.5, 1.0, 2.0, 4.0],\n",
    "    \"ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"max_features\": [10_000, 20_000, 40_000],\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Grid Search\n",
    "for C, ngram_range, max_features in product(param_grid[\"C\"], param_grid[\"ngram_range\"], param_grid[\"max_features\"]):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=ngram_range,\n",
    "        max_features=max_features,\n",
    "        stop_words=\"english\",\n",
    "    )\n",
    "\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_val_vec   = vectorizer.transform(X_val)\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        C=C,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_val_pred = clf.predict(X_val_vec)\n",
    "    mcc = matthews_corrcoef(y_val, y_val_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"C\": C,\n",
    "        \"ngram_range\": str(ngram_range),\n",
    "        \"max_features\": max_features,\n",
    "        \"MCC\": mcc\n",
    "    })\n",
    "\n",
    "# Convertimos los resultados en DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"MCC\", ascending=False)\n",
    "\n",
    "# Mostramos la tabla ordenada por MCC\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo final con los mejores hiperparámetros\n",
    "\n",
    "Una vez identificada la combinación óptima de hiperparámetros mediante la búsqueda realizada en la sección anterior, se entrena el modelo definitivo utilizando **el conjunto completo de entrenamiento**. El objetivo de este bloque es construir el clasificador final que se usará posteriormente para generar las predicciones sobre el conjunto de test.\n",
    "\n",
    "Los hiperparámetros seleccionados fueron:\n",
    "\n",
    "- **C = 4.0:** menor regularización, permitiendo al clasificador ajustar mejor los patrones.\n",
    "\n",
    "- **ngram_range = (1, 3):** uso de unigramas, bigramas y trigramas, lo cual permite capturar expresiones y secuencias léxicas relevantes para identificar mensajes de spam.\n",
    "\n",
    "- **max_features = 20 000:** tamaño del vocabulario TF-IDF que proporciona un buen equilibrio entre representatividad y eficiencia computacional.\n",
    "\n",
    "Con estos parámetros se entrena el vectorizador TF-IDF y el clasificador lineal (*Logistic Regression*) sobre **todo el dataset** disponible, aprovechando así la máxima cantidad de información antes de generar las predicciones finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:57:50.839770Z",
     "iopub.status.busy": "2025-12-12T20:57:50.839471Z",
     "iopub.status.idle": "2025-12-12T20:57:54.115525Z",
     "shell.execute_reply": "2025-12-12T20:57:54.114768Z",
     "shell.execute_reply.started": "2025-12-12T20:57:50.839748Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando mejores parámetros finales:\n",
      "C = 4.0 ngram = (1, 3) max_features = 20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=4.0, class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4.0, class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=4.0, class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos los mejores hiperparámetros de la optimización\n",
    "best_row = results_df.iloc[0]\n",
    "\n",
    "C_best = float(best_row[\"C\"])\n",
    "ngram_best = eval(best_row[\"ngram_range\"])\n",
    "max_feat_best = int(best_row[\"max_features\"])\n",
    "\n",
    "print(\"Usando mejores parámetros finales:\")\n",
    "print(\"C =\", C_best, \"ngram =\", ngram_best, \"max_features =\", max_feat_best)\n",
    "\n",
    "# Vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=ngram_best,\n",
    "    max_features=max_feat_best,\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "\n",
    "# Modelo de clasificación\n",
    "classifier = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=C_best,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "# Fit transform con datos de entrenamiento\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "classifier.fit(X_vec, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:58:03.158608Z",
     "iopub.status.busy": "2025-12-12T20:58:03.158331Z",
     "iopub.status.idle": "2025-12-12T20:58:03.666269Z",
     "shell.execute_reply": "2025-12-12T20:58:03.665443Z",
     "shell.execute_reply.started": "2025-12-12T20:58:03.158586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "y_pred = classifier.predict(X_test_vec).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del modelo NLP básico\n",
    "\n",
    "El modelo NLP básico basado en TF-IDF y regresión logística proporciona un rendimiento sólido en la tarea de clasificación SPAM/NO SPAM, alcanzando valores competitivos de MCC tras la optimización de hiperparámetros.\n",
    "\n",
    "La búsqueda sistemática de hiperparámetros demostró ser clave para mejorar el rendimiento, evidenciando la importancia de ajustar tanto la representación del texto como la regularización del clasificador. En particular, la inclusión de n-grams de mayor tamaño y un vocabulario TF-IDF adecuado permitió capturar patrones léxicos relevantes asociados al spam.\n",
    "\n",
    "A pesar de su simplicidad, este enfoque clásico constituye un baseline robusto y eficiente, que sirve como referencia para evaluar modelos más avanzados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your predictions in a `submission.csv` file for scoring on the [leaderboard](https://www.kaggle.com/competitions/u-tad-spam-not-spam-2025-edition/leaderboard)\n",
    "To submit your notebook click on **Submit to competition** and then **Submit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:58:07.768160Z",
     "iopub.status.busy": "2025-12-12T20:58:07.767328Z",
     "iopub.status.idle": "2025-12-12T20:58:07.785642Z",
     "shell.execute_reply": "2025-12-12T20:58:07.785103Z",
     "shell.execute_reply.started": "2025-12-12T20:58:07.768126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# do not modify this code\n",
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_pred\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:58:09.845530Z",
     "iopub.status.busy": "2025-12-12T20:58:09.844826Z",
     "iopub.status.idle": "2025-12-12T20:58:09.852175Z",
     "shell.execute_reply": "2025-12-12T20:58:09.851580Z",
     "shell.execute_reply.started": "2025-12-12T20:58:09.845504Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>spam_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  spam_label\n",
       "0    7097           0\n",
       "1    7098           1\n",
       "2    7099           0\n",
       "3    7100           0\n",
       "4    7101           0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo NLP importado\n",
    "\n",
    "Como segunda aproximación se emplea un modelo de lenguaje preentrenado basado en la arquitectura **Transformer**, concretamente **DistilBERT**. Este modelo ha sido entrenado previamente sobre grandes volúmenes de texto, lo que le permite aprender representaciones contextuales del lenguaje natural.\n",
    "\n",
    "A diferencia del modelo básico, este enfoque no se basa en una representación fija del texto, sino que genera embeddings dinámicos que tienen en cuenta el contexto completo de cada palabra dentro del mensaje. Esto resulta especialmente útil en tareas como la detección de spam, donde el significado depende fuertemente del contexto.\n",
    "\n",
    "El uso de un modelo preentrenado permite aplicar técnicas de **transfer learning**, reduciendo el tiempo de entrenamiento y mejorando la capacidad de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos para el modelo importado\n",
    "\n",
    "Para el modelo basado en Transformers, el texto se prepara utilizando un **tokenizador específico del modelo DistilBERT**, encargado de convertir cada mensaje en una secuencia de tokens compatible con el modelo.\n",
    "\n",
    "Esta etapa incluye:\n",
    "- Tokenización del texto.\n",
    "- Truncado o padding a una longitud máxima fija.\n",
    "\n",
    "A diferencia del modelo clásico, no se realiza una limpieza del texto, ya que el modelo ha sido preentrenado con texto natural completo y se beneficia de conservar la estructura original del lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:58:40.315191Z",
     "iopub.status.busy": "2025-12-12T20:58:40.314871Z",
     "iopub.status.idle": "2025-12-12T20:58:48.150748Z",
     "shell.execute_reply": "2025-12-12T20:58:48.150174Z",
     "shell.execute_reply.started": "2025-12-12T20:58:40.315166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modelo para transfer learning y fine tunning\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T20:59:02.358398Z",
     "iopub.status.busy": "2025-12-12T20:59:02.357818Z",
     "iopub.status.idle": "2025-12-12T20:59:06.162620Z",
     "shell.execute_reply": "2025-12-12T20:59:06.162063Z",
     "shell.execute_reply.started": "2025-12-12T20:59:02.358372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "\n",
    "def encode(texts):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "enc_train = encode(X_train)\n",
    "enc_val   = encode(X_val)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((dict(enc_train),y_train)).shuffle(2048, seed=seed).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((dict(enc_val),y_val)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "enc_test = encode(test[\"text\"].astype(str).values)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(dict(enc_test)).batch(32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "En la fase de *transfer learning* se congela el encoder del modelo DistilBERT y se entrena únicamente la capa final de clasificación. De este modo, se reutilizan las representaciones semánticas generales aprendidas durante el preentrenamiento, adaptando el modelo al problema específico con un número reducido de parámetros entrenables.\n",
    "\n",
    "Esta estrategia permite un entrenamiento rápido y estable, reduciendo el riesgo de sobreajuste y proporcionando una base sólida antes de realizar ajustes más profundos en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=2, use_safetensors=False)\n",
    "\n",
    "# Congelar capas entrenadas (transfer learning)\n",
    "model.distilbert.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")])\n",
    "\n",
    "history_head = model.fit(train_ds, validation_data=val_ds, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T21:23:58.820964Z",
     "iopub.status.busy": "2025-12-12T21:23:58.820416Z",
     "iopub.status.idle": "2025-12-12T21:24:07.630933Z",
     "shell.execute_reply": "2025-12-12T21:24:07.630022Z",
     "shell.execute_reply.started": "2025-12-12T21:23:58.820940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 9s 156ms/step\n",
      "MCC transfer learning: 0.8692983222653029\n"
     ]
    }
   ],
   "source": [
    "logits_val = model.predict(val_ds).logits\n",
    "y_pred_val = np.argmax(logits_val, axis=1)\n",
    "mcc = matthews_corrcoef(y_val, y_pred_val)\n",
    "print(\"MCC transfer learning:\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "Una vez entrenada la cabeza de clasificación, se procede a una fase de *fine-tuning* parcial del modelo. En esta etapa se descongelan las capas superiores del encoder, permitiendo que el modelo ajuste sus representaciones internas al dominio concreto de los mensajes de spam.\n",
    "\n",
    "El fine-tuning se realiza utilizando una tasa de aprendizaje reducida, con el objetivo de realizar ajustes graduales sin destruir el conocimiento previo aprendido. Esta fase suele producir una mejora significativa en el rendimiento final del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T21:24:10.184026Z",
     "iopub.status.busy": "2025-12-12T21:24:10.183746Z",
     "iopub.status.idle": "2025-12-12T21:31:10.169007Z",
     "shell.execute_reply": "2025-12-12T21:31:10.168376Z",
     "shell.execute_reply.started": "2025-12-12T21:24:10.184004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.distilbert.trainable = True\n",
    "\n",
    "# congelamos todas menos las últimas 2\n",
    "for layer in model.distilbert.transformer.layer[:-2]:\n",
    "    layer.trainable = False\n",
    "for layer in model.distilbert.transformer.layer[-2:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    ")\n",
    "\n",
    "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T21:32:10.306010Z",
     "iopub.status.busy": "2025-12-12T21:32:10.305227Z",
     "iopub.status.idle": "2025-12-12T21:32:17.367754Z",
     "shell.execute_reply": "2025-12-12T21:32:17.367110Z",
     "shell.execute_reply.started": "2025-12-12T21:32:10.305979Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 7s 156ms/step\n",
      "MCC (fine-tuned): 0.93885797199061\n"
     ]
    }
   ],
   "source": [
    "logits_val = model.predict(val_ds).logits\n",
    "y_pred_val = np.argmax(logits_val, axis=1)\n",
    "mcc = matthews_corrcoef(y_val, y_pred_val)\n",
    "print(\"MCC (fine-tuned):\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del modelo importado\n",
    "\n",
    "El modelo basado en DistilBERT logra una mejora respecto al modelo NLP básico, alcanzando valores de MCC significativamente superiores tras el proceso de fine-tuning.\n",
    "\n",
    "Estos resultados muestran la capacidad de los modelos preentrenados para capturar relaciones semánticas complejas y generalizar mejor a ejemplos no vistos. A pesar de su mayor coste computacional, el enfoque basado en Transformers demuestra ser especialmente eficaz para tareas de clasificación de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones generales\n",
    "\n",
    "En este proyecto se han explorado dos enfoques complementarios para la clasificación SPAM/NO SPAM: un modelo NLP clásico basado en TF-IDF y regresión logística, y un modelo avanzado basado en un Transformer preentrenado.\n",
    "\n",
    "El modelo básico ofrece una solución eficiente y fácil de interpretar, mientras que el modelo importado mediante transfer learning proporciona un rendimiento superior gracias a representaciones contextualizadas del lenguaje. La comparación entre ambos enfoques permite apreciar las ventajas y limitaciones de cada uno, así como la evolución natural desde técnicas clásicas hacia modelos modernos en NLP.\n",
    "\n",
    "En conjunto, el proyecto demuestra la importancia de combinar fundamentos teóricos sólidos con modelos avanzados para resolver problemas reales de procesamiento del lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your predictions in a `submission.csv` file for scoring on the [leaderboard](https://www.kaggle.com/competitions/u-tad-spam-not-spam-2025-edition/leaderboard)\n",
    "To submit your notebook click on **Submit to competition** and then **Submit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T21:32:50.657143Z",
     "iopub.status.busy": "2025-12-12T21:32:50.656757Z",
     "iopub.status.idle": "2025-12-12T21:33:14.012782Z",
     "shell.execute_reply": "2025-12-12T21:33:14.012252Z",
     "shell.execute_reply.started": "2025-12-12T21:32:50.657123Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 23s 157ms/step\n"
     ]
    }
   ],
   "source": [
    "logits_test = model.predict(test_ds).logits\n",
    "y_pred_test = np.argmax(logits_test, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T21:33:27.400106Z",
     "iopub.status.busy": "2025-12-12T21:33:27.399808Z",
     "iopub.status.idle": "2025-12-12T21:33:27.412203Z",
     "shell.execute_reply": "2025-12-12T21:33:27.411477Z",
     "shell.execute_reply.started": "2025-12-12T21:33:27.400080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# do not modify this code\n",
    "submission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\n",
    "submission[\"spam_label\"] = y_pred_test\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T21:33:29.419891Z",
     "iopub.status.busy": "2025-12-12T21:33:29.419349Z",
     "iopub.status.idle": "2025-12-12T21:33:29.426755Z",
     "shell.execute_reply": "2025-12-12T21:33:29.425983Z",
     "shell.execute_reply.started": "2025-12-12T21:33:29.419870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>spam_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  spam_label\n",
       "0    7097           0\n",
       "1    7098           1\n",
       "2    7099           0\n",
       "3    7100           0\n",
       "4    7101           0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14338739,
     "sourceId": 119855,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
